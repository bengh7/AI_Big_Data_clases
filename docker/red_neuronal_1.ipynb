{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mq7Wbtxd9Qgw"
      },
      "outputs": [],
      "source": [
        "# importamos Librerías\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_circles"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el DataSet\n",
        "# Usaremos la función make_circles\n",
        "\n",
        "# Definimos variables\n",
        "\n",
        "n = 500 # Número de registros que queremos de los datos\n",
        "p = 2 # Cuántas características tenemos de nuestros datos. Por efectos de visualización, se usa 2 para graficar en un eje de coordenadas bidimensional\n",
        "\n",
        "X,Y = make_circles(n_samples=n, factor= 0.5,noise=0.05) # \"factor\" hacer referencia a el factor de escala entre el circulo interior y el exterior\n",
        "# 'noise' hace referencia a la desviación estándar Gaussiana agregada a los datos\n",
        "\n",
        "Y = Y[:,np.newaxis]\n",
        "\n",
        "plt.scatter(X[:,0],X[:,1]);"
      ],
      "metadata": {
        "id": "APzpLYdZ9pKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sim embargo vamos a graficarlo de forma más \"bonita\":\n",
        "# Puntos de la circunferencia\n",
        "\n",
        "# Notemos que al imprimir Y, nos dan 0 y 1\n",
        "\n",
        "# print(Y)"
      ],
      "metadata": {
        "id": "pUx7rDYaIXD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Por lo tanto solo graficamos cuando y = 0\n",
        "\n",
        "plt.scatter(X[Y[:,0]==0,0],X[Y[:,0]==0,1],c=\"skyblue\");\n",
        "plt.scatter(X[Y[:,0]==1,0],X[Y[:,0]==1,1],c=\"salmon\");\n",
        "plt.axis(\"equal\");"
      ],
      "metadata": {
        "id": "CSoGomLI_Do0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CLASE DE LA CAPA DE LA RED\n",
        "\n",
        "  # Creamos una clase:\n",
        "  # Esto es una estructura de datos que contiene los parámetros e información de nuestra red neuronal\n",
        "  # Esto ayuda a crear capas\n",
        "  # Se llamará \"neural_layer\":\n",
        "\n",
        "\n",
        "class neural_layer():\n",
        "\n",
        "  def __init__(self,n_conn,n_neur,act_f):\n",
        "    self.act_f = act_f\n",
        "\n",
        "    self.b = np.random.rand(1,n_neur) * 2 - 1\n",
        "    self.W = np.random.rand(n_conn,n_neur) * 2 - 1"
      ],
      "metadata": {
        "id": "E0lmyghk_zTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sim embargo vamos a graficarlo de forma más \"bonita\":\n",
        "# Puntos de la circunferencia\n",
        "\n",
        "# Notemos que al imprimir Y, nos dan 0 y 1\n",
        "\n",
        "#print(Y)"
      ],
      "metadata": {
        "id": "YrkFOSOjFzUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funciones de Activación\n",
        "\n",
        "#  La sigmoide y su derivada se saca para mayor facilidad de una vez a la hora de calcular el error\n",
        "\n",
        "sigm = (lambda x: 1 / (1+np.e**(-x)),\n",
        "        lambda x: x * ( 1 - x ))\n",
        "\n",
        "relu = lambda x: np.maximum(0,x)\n",
        "\n",
        "#Ejemplo\n",
        "\n",
        "_x = np.linspace(-5,5,100)\n",
        "plt.plot(_x,sigm[0](_x))"
      ],
      "metadata": {
        "id": "EhjmPfhdHNpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Empezamos a diseñar capas\n",
        "\n",
        "# l0 => Layer #0\n",
        "\n",
        "l0 = neural_layer(p,4,sigm)\n",
        "l1 = neural_layer(4,8,sigm)\n",
        "\n",
        "\n",
        "#----\n",
        "#Definimos la función que cree la red neural\n",
        "\n",
        "\n",
        "\n",
        "def create_nn(topology,act_f):\n",
        "\n",
        "  nn = []\n",
        "\n",
        "  for l, layer in enumerate(topology[:-1]):\n",
        "\n",
        "    nn.append(neural_layer(topology[l],topology[l+1],act_f))\n",
        "\n",
        "  return nn\n",
        "\n",
        "\n",
        "\n",
        "topology = [2,4,8,16,8,4,1] #Las capas que tendrá la red\n",
        "\n",
        "create_nn(topology,sigm)"
      ],
      "metadata": {
        "id": "IbvmJ0dmHTsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a definir el entrenamiento de la red neuronal\n",
        "\n",
        "\n",
        "topology = [p,4,8,1] # Lo ajustamos\n",
        "\n",
        "neural_net = create_nn(topology,sigm)\n",
        "\n",
        "l2_cost = (lambda Yp,Yr: np.mean((Yp - Yr) ** 2),\n",
        "           lambda Yp,Yr: (Yp - Yr))\n",
        "\n",
        "def train(neural_net,X,Y,l2_cost,lr=0.5,train=True):\n",
        "\n",
        "  out = [(None,X)]\n",
        "\n",
        "  # Forward Pass\n",
        "  # @ es multiplicación matricial\n",
        "\n",
        "  for l,layer in enumerate(neural_net):\n",
        "\n",
        "    z = out[-1][1] @ neural_net[l].W + neural_net[l].b\n",
        "    a = neural_net[l].act_f[0](z)\n",
        "\n",
        "    out.append((z,a))\n",
        "    # print(out[-1][1].shape)\n",
        "\n",
        "  # print(l2_cost[0](out[-1][1],Y))\n",
        "\n",
        "\n",
        "  if train:\n",
        "\n",
        "    # Backward pass\n",
        "    deltas = []\n",
        "\n",
        "    for l in reversed(range(0,len(neural_net))):\n",
        "\n",
        "      z = out[l+1][0]\n",
        "      a = out[l+1][1]\n",
        "\n",
        "\n",
        "      if l == len(neural_net) - 1:\n",
        "\n",
        "        deltas.insert(0,l2_cost[1](a,Y)*neural_net[l].act_f[1](a))\n",
        "\n",
        "        #Calcular Delta última capa\n",
        "      else:\n",
        "\n",
        "        deltas.insert(0,deltas[0] @ _W.T * neural_net[l].act_f[1](a))\n",
        "\n",
        "      _W = neural_net[l].W\n",
        "\n",
        "      # Gradient Descent\n",
        "\n",
        "      neural_net[l].b = neural_net[l].b - np.mean(deltas[0],axis=0,keepdims=True) * lr\n",
        "      neural_net[l].W = neural_net[l].W - out[l][1].T @ deltas[0] * lr\n",
        "\n",
        "  return out[-1][1]\n",
        "\n",
        "\n",
        "train(neural_net,X,Y,l2_cost,0.5)\n",
        "print('')"
      ],
      "metadata": {
        "id": "szFcHsGZHoZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vamos a ver cómo queda nuestro proceso\n",
        "\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "neural_net = create_nn(topology,sigm)\n",
        "\n",
        "loss = []\n",
        "\n",
        "for i in range (10000):\n",
        "\n",
        "\n",
        "  # Entrenemos a la red:\n",
        "\n",
        "  pY = train(neural_net,X,Y,l2_cost,lr=0.03)\n",
        "\n",
        "  if i % 25 == 0:\n",
        "\n",
        "    # print(pY)\n",
        "\n",
        "    loss.append(l2_cost[0](pY,Y))\n",
        "\n",
        "    res = 50\n",
        "\n",
        "    _x0 = np.linspace(-1.5,1.5,res)\n",
        "    _x1 = np.linspace(-1.5,1.5,res)\n",
        "\n",
        "    _Y = np.zeros((res,res))\n",
        "\n",
        "    for i0, x0 in enumerate(_x0):\n",
        "\n",
        "      for i1, x1 in enumerate(_x1):\n",
        "\n",
        "        _Y[i0,i1] = train(neural_net, np.array([[x0,x1]]),Y,l2_cost,train=False)[0][0]\n",
        "\n",
        "    plt.pcolormesh(_x0,_x1,_Y,cmap=\"coolwarm\")\n",
        "    plt.axis('equal')\n",
        "\n",
        "    plt.scatter(X[Y[:,0] == 0,0],X[Y[:,0] == 0,1], c=\"skyblue\")\n",
        "    plt.scatter(X[Y[:,0] == 1,0],X[Y[:,0] == 1,1], c=\"salmon\")\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    plt.show()\n",
        "    plt.plot(range(len(loss)),loss)\n",
        "    plt.show()\n",
        "    time.sleep(0.2)\n",
        "    #print('iteración #', i)"
      ],
      "metadata": {
        "id": "6ywDrjgZI6AR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}