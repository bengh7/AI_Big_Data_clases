{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ff84723-7b46-4120-a6f9-d52df7451c25",
   "metadata": {},
   "source": [
    "Actividad: Tipos de Datos y Adquisición de\n",
    "Datos en Python\n",
    "Parte 2: Adquisición y Almacenamiento de Datos\n",
    "Objetivos:\n",
    "\n",
    "● Aprender cómo obtener datos de fuentes externas (APIs, web scraping).\n",
    "● Aprender a almacenar los datos adquiridos en archivos adecuados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14ae642-6f82-49be-a3fc-19138ae0679c",
   "metadata": {},
   "source": [
    "Instrucciones Paso a Paso\n",
    "1. Investigación Teórica (1 hora)\n",
    "Objetivo: Entender cómo funcionan las APIs, el web scraping y la conexión con\n",
    "bases de datos.\n",
    "\n",
    "1. Lee sobre las siguientes técnicas de adquisición de datos:\n",
    "\n",
    "   \n",
    "    ○ APIs: Son interfaces que permiten interactuar con servicios\n",
    "externos para obtener datos. Por ejemplo, puedes obtener datos de\n",
    "Twitter, OpenWeather o cualquier otra fuente pública.\n",
    "\n",
    "\n",
    "    ○ Web Scraping: Consiste en extraer datos de sitios web\n",
    "automáticamente. Se usan herramientas como BeautifulSoup o Scrapy.\n",
    "\n",
    "\n",
    "    ○ Bases de Datos: Son sistemas de almacenamiento de datos\n",
    "organizados. Puedes acceder a ellas desde Python usando\n",
    "bibliotecas como sqlite3 o SQLAlchemy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b93087-9a18-44b7-ac2b-8a09d6f2d2af",
   "metadata": {},
   "source": [
    "1. Las APIs son interfaces que permiten que diferentes aplicaciones se comuniquen entre sí.\n",
    "Para obtener datos de una API, generalmente se realiza una solicitud HTTP a un servidor,\n",
    "que responde con datos en formatos como JSON o XML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9415c17-f634-4561-b808-559661ffdb94",
   "metadata": {},
   "source": [
    "2. Web Scraping\n",
    "El web scraping permite extraer información de sitios web de forma automática. Se usa cuando una API no está disponible o no proporciona los datos requeridos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ea76f-5382-41fd-98d3-ff5c9c8dde52",
   "metadata": {},
   "source": [
    "3. Bases de Datos\n",
    "Las bases de datos permiten almacenar, organizar y recuperar información estructurada. En Python, puedes interactuar con bases de datos como SQLite, MySQL o PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e745c59-8105-4278-9212-992c82d6d3db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd2e24b-4803-40ff-b7a9-c10d197643df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a070166-d6ec-43c9-a765-34f82bd2910c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7174c24-3494-4760-bef1-86aea3f45380",
   "metadata": {},
   "source": [
    "2. Responde las siguientes preguntas en tu informe:\n",
    "   \n",
    "    ○ ¿Qué es una API y cómo puedes interactuar con ellas para obtener\n",
    "datos?\n",
    "\n",
    "    ○ ¿Cuál es la diferencia entre el web scraping y el uso de APIs?\n",
    "   \n",
    "    ○ ¿Cómo puedes almacenar los datos adquiridos de una API o scraping\n",
    "en un archivo CSV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acf16e6-f950-478a-829f-b0f709282a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f394c81a-e045-460f-88cd-1bcf2d6581ac",
   "metadata": {},
   "source": [
    "2. Actividad Práctica\n",
    "Objetivo: Obtener datos de una API pública y almacenarlos en un archivo CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffc5adc-3876-4a32-9e13-30e7171b8b7f",
   "metadata": {},
   "source": [
    "1. Trabajo con una API (Ejemplo con OpenWeather):\n",
    "2. \n",
    "    ○ Paso 1: Regístrate en OpenWeatherMap y obtén una clave API.\n",
    "   \n",
    "    ○ Paso 2: Usa la biblioteca requests en Python para obtener datos\n",
    "del clima. El siguiente código te ayudará a hacer una solicitud a\n",
    "la API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8388a7a3-9583-4e1a-8291-89deb8091997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "api_key = 'tu_clave_api'\n",
    "url = f'http://api.openweathermap.org/data/2.5/weather?q=London&appid={api_key}'\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "# Muestra los datos obtenidos\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6af30ad-5549-4119-9c1d-12e90c7992da",
   "metadata": {},
   "source": [
    "○ Paso 3: Almacena los datos en un archivo CSV. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86b15c-607e-4ec2-b7f5-a9fb29a43f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supón que 'data' tiene la información del clima\n",
    "df = pd.DataFrame([data])\n",
    "df.to_csv('clima_london.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797d9d6-f577-41b1-905d-2d9c34447a83",
   "metadata": {},
   "source": [
    "2. Trabajo con Web Scraping (Ejemplo con BeautifulSoup):\n",
    "○ Paso 1: Instala BeautifulSoup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b92846b-ebf8-445f-a2cc-333081892bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install beautifulsoup4 requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd83dde-b5a9-48d6-a3fa-ada8f2689f0e",
   "metadata": {},
   "source": [
    "Paso 2: Realiza scraping de un sitio web (por ejemplo, extraer los\n",
    "títulos de noticias de un sitio):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68423323-2700-42ff-85ca-8877fe3fb7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # Importamos BeautifulSoup para analizar el\n",
    "contenido HTML\n",
    "import requests # Importamos la librería requests para hacer peticiones HTTP\n",
    "# Definimos la URL del sitio web que queremos scrape\n",
    "url = 'https://www.bbc.com'\n",
    "# Realizamos la solicitud HTTP al sitio web y obtenemos la respuesta\n",
    "response = requests.get(url)\n",
    "# Usamos BeautifulSoup para analizar el contenido de la respuesta en formato HTML\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "# Buscamos todas las etiquetas <h2> en el contenido HTML, que deberían contener los\n",
    "titulares\n",
    "headlines = soup.find_all('h2')\n",
    "# Almacenamos los titulares en una lista\n",
    "titles = []\n",
    "# Recorremos cada uno de los elementos encontrados\n",
    "for headline in headlines:\n",
    "text = headline.text.strip()\n",
    "if text: # Solo añadimos si no está vacío\n",
    "titles.append(text)\n",
    "# Imprimimos todos los titulares juntos, cada uno en una línea\n",
    "print(\"\\n\".join(titles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c64c85-2444-4a89-93c4-89014379c97d",
   "metadata": {},
   "source": [
    "○ Paso 3: Almacena los datos obtenidos en un archivo CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f1158-b6d9-4d90-a19b-abde3e33ada0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc347ce5-341a-44e2-a7f4-08565ee08974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
